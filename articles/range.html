<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-12-30 Tue 22:12 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Range Review</title>
<meta name="author" content="Eryk Banatt" />
<meta name="generator" content="Org Mode" />
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-101739190-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-101739190-1');
</script>


<link  href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/js/bootstrap.min.js"></script>

<script>
var shiftWindow = function() { scrollBy(0, -50) };
if (location.hash) shiftWindow();
window.addEventListener("hashchange", shiftWindow);
</script>

<script type="text/javascript">

$(function() {
    'use strict';

    $("#text-table-of-contents ul:first").addClass('nav')
    $('body').attr('data-spy', 'scroll')
    $('body').attr('data-target', '#text-table-of-contents')
    $('body').attr('data-offset', '100')
    $('table').addClass('table table-striped table-bordered table-hover table-condensed')

    // Dark mode functionality
    window.toggleDarkMode = function() {
        document.body.classList.toggle('dark-mode');
        const isDarkMode = document.body.classList.contains('dark-mode');
        localStorage.setItem('darkMode', isDarkMode);
        updateToggleButton();
    }

    function updateToggleButton() {
        const toggle = document.querySelector('.dark-mode-toggle-nav');
        if (toggle) {
            toggle.innerHTML = document.body.classList.contains('dark-mode') ? '‚òÄÔ∏è' : 'üåô';
        }
    }

    // Initialize dark mode from localStorage
    const savedDarkMode = localStorage.getItem('darkMode');
    if (savedDarkMode === 'true') {
        document.body.classList.add('dark-mode');
    }

    // Update toggle button on page load
    updateToggleButton();
});
</script>

<link rel="stylesheet" type="text/css" href="https://planetbanatt.net/css/default_20240614.css" />
<link rel="shortcut icon" type="image/jpg" href="https://planetbanatt.net/favicon.ico" />
</head>
<body>
<div id="preamble" class="status">

<!-- heading -->
<!-- add here -->

<!-- Fixed navbar -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>

        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav ml-auto" style="margin-left:3%">
            <li class="nav-item"><a href="http://planetbanatt.net/">Home</a></li>
            <li><a href="http://planetbanatt.net/about.html">About</a></li>
            <li><a href="http://planetbanatt.net/projects.html">Projects</a></li>
            <li><a href="http://planetbanatt.net/melee/index.html">Melee</a></li>
            <li><a href="http://planetbanatt.net/links.html">Links</a></li>
            <li><a href="http://planetbanatt.net/resume.pdf">Resume</a></li>
            <li class="dark-mode-nav-item"><a href="#" class="dark-mode-toggle-nav" onclick="toggleDarkMode(); return false;">üåô</a></li>
          </ul>
          </ul>
        </div><!--/.nav-collapse -->
    </nav>
</div>
<div id="content" class="content">
<h1 class="title">Range Review</h1>
<div id="table-of-contents" role="doc-toc">
<h1>Table of Contents</h1>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgba8e0ea">Range</a>
<ul>
<li><a href="#orga428952">Introduction: Roger vs. Tiger</a></li>
<li><a href="#orgfc5e5b9">Chapter 1: The Cult of the Head Start</a></li>
<li><a href="#orgda4fcfc">Chapter 2: How the Wicked World Was Made</a></li>
<li><a href="#org6303198">Chapter 3: When Less of the Same Is More</a></li>
<li><a href="#org4773a23">Chapter 4: Learning, Fast and Slow</a></li>
<li><a href="#org3c81a4d">Chapter 5: Thinking Outside Experience</a></li>
<li><a href="#org60838c4">Chapter 6: The Trouble with Too Much Grit</a></li>
<li><a href="#org008927a">Chapter 7: Flirting with Your Possible Selves</a></li>
<li><a href="#orgbe4eb84">Chapter 8: The Outsider Advantage</a></li>
<li><a href="#org8d0ac4b">Chapter 9: Lateral Thinking with Withered Technology</a></li>
<li><a href="#orge81df1d">Chapter 10: Fooled by Expertise</a></li>
<li><a href="#orgf6760b6">Chapter 11: Learning to Drop Your Familiar Tools</a></li>
<li><a href="#org540bd6e">Chapter 12: Deliberate Amateurs</a></li>
<li><a href="#org0668c72">Conclusion: Expanding Your Range</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgba8e0ea" class="outline-1">
<h1 id="orgba8e0ea">Range</h1>
<div class="outline-text-1" id="text-orgba8e0ea">
<p>
Please see my goodreads review for a broader overview of this book.
</p>

<p>
What follows in this review is a brief overview of specific ideas in the book which I think are worth writing down &#x2013; the above can be viewed as the big-picture review of the book, whereas the below can be thought of as a sort of prose outline of notes for the book. I'm planning on going back and finding the papers which I have labeled as "citations", but for now I'll just leave them as they are here.
</p>
</div>

<div id="outline-container-orga428952" class="outline-2">
<h2 id="orga428952">Introduction: Roger vs. Tiger</h2>
<div class="outline-text-2" id="text-orga428952">
<p>
The book begins with a comparison between Roger Federer and Tiger Woods. Both world champions, Tiger was groomed from birth to be good at golf whereas Federer played tons of sports and eventually decided he liked tennis the best, rather late in life. Tiger represents the Gladwell "Deliberate Practice" and "10,000 hours" rules, but Roger does not, and there's contentious reserch about a "sampling period" being useful for up-and-comers during selection of a sport. Compare to the Pat Tillman foundation, which comprises accomplished military veterans amidst career switches. 
</p>

<p>
Citations
Late Specialization: The Key to Success
Making it to the Top in Team Sports: Start Later, Intensify, and Be Determined
German national team soccer study
</p>
</div>
</div>

<div id="outline-container-orgfc5e5b9" class="outline-2">
<h2 id="orgfc5e5b9">Chapter 1: The Cult of the Head Start</h2>
<div class="outline-text-2" id="text-orgfc5e5b9">
<p>
Lazlo Polgar is a frequently cited figure in the learning-skills-very-well literature, mostly because of his book <i>Bring Up Genius!</i> where he talks about how he was able to raise all his daughters to be highly elite chess players by specializing heavily from birth. Books like <i>Talent is Overrated</i> frequently cite this concept, but it's contentious when you try to generalize to other activities for samples greater than a single family. In particular, the Kahneman and Klein 2009 idea of <b>kind learning environments</b> and <b>wicked learning environments</b> is a critical one, corresponding to environments where pattern recognition is pretty much the entire game, versus environments where the reward signal is sparse and hard to figure out. Some of the research in AI is referenced here, and broadly speaking the more wicked an environment is the more likely it would be a hard problem for AI to defeat humans at, and vice versa. The starcraft example is often touted as reinforcement learning being able to improve at wicked problems but I still feel pretty strongly about it being IBM Watson-style superhuman biological performance rather than superior strategy or reasoning. 
</p>

<p>
Citations
Most of the canonical expertise literature is cited in this chapter: Klein's NDM, de Groot / Chase et al "chunking" studies, Treffert's work on savants
</p>

<p>
Schwartz: how to not teach people to discover rules
Connoly and Gobet career streams
</p>
</div>
</div>

<div id="outline-container-orgda4fcfc" class="outline-2">
<h2 id="orgda4fcfc">Chapter 2: How the Wicked World Was Made</h2>
<div class="outline-text-2" id="text-orgda4fcfc">
<p>
The flynn effect is a byproduct of global culture getting progressively more oriented towards abstract categorical thinking, even when more crystallized intellect measures like math and reading scores don't improve at all. The idea here is "scientific spectacles" which is, to use machine learning speak, overfitting to a world which uses abstract categories, and thereby scoring higher on tests which measure abstract categorical thinking. There are some "adversarial attacks" which arise from this, like the Ebbinghaus illusion, but it does improve IQ scores (analogy mine). "No tool is omnicompetent"
</p>
</div>
</div>

<div id="outline-container-org6303198" class="outline-2">
<h2 id="org6303198">Chapter 3: When Less of the Same Is More</h2>
<div class="outline-text-2" id="text-org6303198">
<p>
The figlie was famously comprised of orphans, often with disabilities, who were taught to play many instruments and were a world-class musical troupe with Vivaldi writing pieces for them to play. A brief discussion of the relatively psycho "Battle Hymn of the Tiger Mother". A lot of the literature (see: cambridge handbook on expertise and expert performance) on musical performance focuses on classical training, which is a much kinder learning environment compared to other musical disciplines based on improvisation, and the two are notably different when it comes to where the specialization period begins. Bunch of examples of musicians who started late. 
</p>
</div>
</div>

<div id="outline-container-org4773a23" class="outline-2">
<h2 id="org4773a23">Chapter 4: Learning, Fast and Slow</h2>
<div class="outline-text-2" id="text-org4773a23">
<p>
Public education frequently overfits to getting answers right by learning how to query the teacher and solve problems that will appear in front of them very soon, but don't generalize well to new problems. Higher performing countries are typically operating inside much more wicked learning environments, which allow students to generalize better and make connections which allow them to solve new problems. Critically, you learn the best when you are stressing the boundaries and actually pushing some degree of desirable difficulty (obvious analogy: lifting weights). There's some discussion on the spacing effect, which is obviously well documented (see gwerns Spaced Repetition writeup <a href="https://www.gwern.net/Spaced-repetition">https://www.gwern.net/Spaced-repetition</a>). Head Start programs have a notable fadeout effect where other kids catch up (Duncan and Bailey 2017). Generalization is the most important thing.
</p>

<p>
Kornell animal cognition research about memorizing lists with hints harming performance
Kornell and Metcalfe vocabulary study which demonstrated randomly guessing meaning of new words first increased retention (hypercorrection)
Kornell and Bjork's interleaving mixed-practice study, outperforms blocked practice despite doing way worse in training and feeling like they are worse at it.
</p>
</div>
</div>

<div id="outline-container-org3c81a4d" class="outline-2">
<h2 id="org3c81a4d">Chapter 5: Thinking Outside Experience</h2>
<div class="outline-text-2" id="text-org3c81a4d">
<p>
Kepler was able to grapple with new fields of science by making an impressive number of analogies, and analogies are extremely useful tools for helping conceptualize abstract concepts. Teams with varied specializations typically perform better at solving previously unsolved problems compared to teams comprised of many from the same specialization. In machine learning parlance, this is because <i>ensembles</i> perform better with <i>decorrelated errors</i> &#x2013; if all of your agents are making the same mistakes, then having 9 of them is hardly any better than having just 1 of them, but if your agents make mistakes in different spots, then the collection of their answers is likely to be more accurate then any individual one's answers. 
</p>

<p>
Citations
Duncker 1930
Gentner ambiguous sorting task
Kevin Dunbar productive labs 1990 (definitely read this later)
</p>
</div>
</div>

<div id="outline-container-org60838c4" class="outline-2">
<h2 id="org60838c4">Chapter 6: The Trouble with Too Much Grit</h2>
<div class="outline-text-2" id="text-org60838c4">
<p>
<i>Grit</i> is often mentioned as a good thing, but jumping between fields and tasks can occasionally just be seen as optimizing ruthlessly for "Match Quality" (see: Ofer Malmud's work). If you fit better in field B than field A, then leaving field A doesn't make you stupid, it makes you smart. ‚ÄúThe benefits to increased match quality&#x2026; outweigh the greater loss in skills.‚Äù Put in a somewhat depressing way, talent probably helps, but finding the thing you're most talented at is probably a better use of your time compared to just tunnel visioning on one thing. West point cadets more likely to get big scholarships from the military are much more likely to actually just leave the military, because they can probably do better elsewhere, which is annoying for the military since they would prefer to give scholarships to potential career officers which are virtually impossible to identify.
</p>

<p>
Citations
Very famous coin flip study - Levitt 
</p>
</div>
</div>

<div id="outline-container-org008927a" class="outline-2">
<h2 id="org008927a">Chapter 7: Flirting with Your Possible Selves</h2>
<div class="outline-text-2" id="text-org008927a">
<p>
Most people think they're at the endpoint of changing themselves, but they're basically never right (the End of History Illusion). This chapter is mostly anecdotes, but the gist of it is that you should feel good about flirting with the idea of redefinining yourself, because it's sometimes very hard to know how much you will like something.
</p>

<p>
Todd Rose Dark Horse Project
"Context Principle" Ogas and Rose 2007 - people are frequently different personalities depending on what situation where they are in.
Marshmallow Test
</p>
</div>
</div>

<div id="outline-container-orgbe4eb84" class="outline-2">
<h2 id="orgbe4eb84">Chapter 8: The Outsider Advantage</h2>
<div class="outline-text-2" id="text-orgbe4eb84">
<p>
It's frequent that fields often need a fresh perspective on a problem everybody with appropriate expertise is too entrenched to solve (<i>beginner's mind</i>). Sometimes this is due to outsiders just being gifted (there was a paper I read once about physics students frequently making huge breakthroughs once they switch to obscure fields, and the conclusion was a very striking "gifted individuals gravitate towards fields where they will make the least impact", but I can't find it so maybe I dreamt it or something) but a lot of the time it's just that using new tools to solve an existing problem is necessary, and outside the scope of expert knowledge of that field. <i>InnoCentive</i> is an example of this sort of thinking taken to the extreme, where most of the solvers do better the further they are from their field. <i>Kaggle</i> is also mentioned here, but my personal opinion is that the representation is overblown &#x2013; Kaggle winners very rarely make huge meaningful breakthroughs and the leaderboard is more about hyperparameter tuning established best-models with maybe some small creative components involved. 
</p>

<p>
Anyways, central thesis of this chapter is that knowledge generated by specialists are useful fuel for generalists to connect the dots between seemingly unrelated fields.
</p>
</div>
</div>

<div id="outline-container-org8d0ac4b" class="outline-2">
<h2 id="org8d0ac4b">Chapter 9: Lateral Thinking with Withered Technology</h2>
<div class="outline-text-2" id="text-org8d0ac4b">
<p>
History of Nintendo, which pivot many times from hanafuda playing cards to, ultimately, video games. I actually didn't know a lot of the history of this company, which was fun to hear about. Gunpei Yokoi was pivotal in the ultimate move towards toys and eventually games, and was the original source of Nintendo's persistent attitude about using older technology in new ways rather than trying to compete at the edge technologically ("Lateral thinking with withered technology"). Yokoi was famous for encouraging even the dumbest sounding ideas to be voiced at meetings, because random things being linked together was so important to their business model. 
</p>

<p>
Freeman Dyson wrote in 2009 about "Frogs vs Birds", which should both exist to advance science (one looks at big pictures, one looks at details in mud). Andy Ouderkirk mentions 3M's invention process was heavily dominated by polymaths or "T-shaped people" who had some expertise in one area but dabbled in lots of other stuff and leveraged other people's expertise in intelligent ways. Bunch of smaller anecdotes (comic books, comedy).
</p>
</div>
</div>

<div id="outline-container-orge81df1d" class="outline-2">
<h2 id="orge81df1d">Chapter 10: Fooled by Expertise</h2>
<div class="outline-text-2" id="text-orge81df1d">
<p>
Hyperspecialists very rarely generalize, and make horrible predictors outside their very narrow field (and even frequently inside their own field). <i>Superforecasters</i> is a book I've been meaning to read, but the ultimate tl;dr on it is that the best forecasters read many fields voraciously and work together like an ensemble with very decorrelated errors, sharing information and updating their beliefs. (foxes vs hedgehogs)
</p>

<p>
If you want your opinion to be closer to correct, you need to be actively looking to falsify your own beliefs as much as possible and change your mind as much as necessary.
</p>

<p>
active open-mindedness - Jonathan Baron
</p>
</div>
</div>

<div id="outline-container-orgf6760b6" class="outline-2">
<h2 id="orgf6760b6">Chapter 11: Learning to Drop Your Familiar Tools</h2>
<div class="outline-text-2" id="text-orgf6760b6">
<p>
The Carter Racing study is a phenomenal case study for being aware of information you have and don't have. They had examples of temperature data during the rocket booster failures, where the temperature of failures during testing failed a bunch between 53 degrees and 71 degrees and the frequency didn‚Äôt seem to increase as it got colder so people at NASA thought it would probably be ok even though it was going to be very cold that day. But if you include the data from the non-failed tests and the temperature, you realize easily that every launch under 65 degrees would always fail every single try, and that you didn‚Äôt see the relationship because you didn‚Äôt have any negative examples. Critically, if you only have positive examples, you sort of just have no information unless you are extremely in distribution.
</p>

<p>
There's a lot of anecdotes about being comfortable abandoning your familiar skillsets, but the anecdotes fall flat for me because a lot of them reek of hindsight bias. You can likely always find something small which can make you nervous enough if n=2 is a sample size of weird events enough to make you uncomfortable, so treating this challenger blowby situation as a lapse in judgement rather than a sort of weighted random guess is a little ludicrous to me. It's certainly nicer to NASA compared to just missing data in the Carter Racing version, but the claim that the decision to abandon procedure based on this hunch is just amazingly easy to say in hindsight knowing that ended up being the exact thing that went wrong. Same deal with Lesmes anecdote.
</p>

<p>
Main points are nice, but the anecdotes were weak in this chapter and there was comparatively little science in it. 
</p>
</div>
</div>

<div id="outline-container-org540bd6e" class="outline-2">
<h2 id="org540bd6e">Chapter 12: Deliberate Amateurs</h2>
<div class="outline-text-2" id="text-org540bd6e">
<p>
Finding joy in experimentation is pretty important! "Don't end up a clone of your thesis adviser" is great advice. There's some points about base rate neglect in here which I don't think is super well represented since I think the research about that problem suggests that it's just posed in a confusing way (Tennenbaum and Goodman have a paper somewhere about reframing the problem, still with percentages, that most science people get right immediately). This was the chapter I felt the most strongly about with regards to cogsci though, like the point about most disciplines being like guilds which teach a repertoire or trade rather than solving the problems with the best possible tools.
</p>
</div>
</div>

<div id="outline-container-org0668c72" class="outline-2">
<h2 id="org0668c72">Conclusion: Expanding Your Range</h2>
<div class="outline-text-2" id="text-org0668c72">
<p>
Don't give up, frequently people with range have super flops and unfinished projects but that just makes it more nice when your good idea ends up as good as it does. 
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<a href="#top">Back to Top</a>
</div>
</body>
</html>
