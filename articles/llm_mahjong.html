<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-12-27 Sat 19:31 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Riichi Mahjong LLM</title>
<meta name="author" content="Eryk Banatt" />
<meta name="generator" content="Org Mode" />
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-101739190-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-101739190-1');
</script>


<link  href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/js/bootstrap.min.js"></script>

<script>
var shiftWindow = function() { scrollBy(0, -50) };
if (location.hash) shiftWindow();
window.addEventListener("hashchange", shiftWindow);
</script>

<script type="text/javascript">

$(function() {
    'use strict';

    $("#text-table-of-contents ul:first").addClass('nav')
    $('body').attr('data-spy', 'scroll')
    $('body').attr('data-target', '#text-table-of-contents')
    $('body').attr('data-offset', '100')
    $('table').addClass('table table-striped table-bordered table-hover table-condensed')

    // Dark mode functionality
    window.toggleDarkMode = function() {
        document.body.classList.toggle('dark-mode');
        const isDarkMode = document.body.classList.contains('dark-mode');
        localStorage.setItem('darkMode', isDarkMode);
        updateToggleButton();
    }

    function updateToggleButton() {
        const toggle = document.querySelector('.dark-mode-toggle-nav');
        if (toggle) {
            toggle.innerHTML = document.body.classList.contains('dark-mode') ? '‚òÄÔ∏è' : 'üåô';
        }
    }

    // Initialize dark mode from localStorage
    const savedDarkMode = localStorage.getItem('darkMode');
    if (savedDarkMode === 'true') {
        document.body.classList.add('dark-mode');
    }

    // Update toggle button on page load
    updateToggleButton();
});
</script>

<link rel="stylesheet" type="text/css" href="https://planetbanatt.net/css/default_20240614.css" />
<link rel="shortcut icon" type="image/jpg" href="https://planetbanatt.net/favicon.ico" />
</head>
<body>
<div id="preamble" class="status">

<!-- heading -->
<!-- add here -->

<!-- Fixed navbar -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>

        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav ml-auto" style="margin-left:3%">
            <li class="nav-item"><a href="http://planetbanatt.net/">Home</a></li>
            <li><a href="http://planetbanatt.net/about.html">About</a></li>
            <li><a href="http://planetbanatt.net/projects.html">Projects</a></li>
            <li><a href="http://planetbanatt.net/melee/index.html">Melee</a></li>
            <li><a href="http://planetbanatt.net/links.html">Links</a></li>
            <li><a href="http://planetbanatt.net/resume.pdf">Resume</a></li>
            <li class="dark-mode-nav-item"><a href="#" class="dark-mode-toggle-nav" onclick="toggleDarkMode(); return false;">üåô</a></li>
          </ul>
          </ul>
        </div><!--/.nav-collapse -->
    </nav>
</div>
<div id="content" class="content">
<h1 class="title">Riichi Mahjong LLM</h1>
<div id="table-of-contents" role="doc-toc">
<h1>Table of Contents</h1>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orga3e3ab4">Teaching LLMs to Play Mahjong</a>
<ul>
<li><a href="#org1ada0c9">Abstract</a></li>
<li><a href="#org260f94b">Introduction and Related Work</a></li>
<li><a href="#orgb0a54fd">Gathering Data</a></li>
<li><a href="#org37533e7">Training</a>
<ul>
<li><a href="#orgbf7a0c5">Napkin Test I</a></li>
<li><a href="#org0f76577">Training Run I</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orga3e3ab4" class="outline-1">
<h1 id="orga3e3ab4">Teaching LLMs to Play Mahjong</h1>
<div class="outline-text-1" id="text-orga3e3ab4">
</div>
<div id="outline-container-org1ada0c9" class="outline-2">
<h2 id="org1ada0c9">Abstract</h2>
<div class="outline-text-2" id="text-org1ada0c9">
<p>
Riichi Mahjong hits the sweetspot for LLM-as-game-playing-agent experimentation. It has plentiful high-level data, it's well described as text, it's easily described in a markovian way, and it doesn't have lots of easily available engines for it already. In this work I teach an LLM how to get good at mahjong. The goal is threefold: first, to train a language model to play the game better than me; second, to lay the foundation for a mahjong model which can explain why moves are good or bad; third, to reproduce some interesting papers I read recently on a novel environment. 
</p>
</div>
</div>

<div id="outline-container-org260f94b" class="outline-2">
<h2 id="org260f94b">Introduction and Related Work</h2>
<div class="outline-text-2" id="text-org260f94b">
<p>
Lots of work has been done on training LLMs to perform well at games, mostly popular traditional ones like Chess. I won't go into too much detail about everything out there (since this is a get-hands-dirty holiday break project) but two papers are standouts motivating my approach here. 
</p>

<p>
<a href="https://arxiv.org/pdf/2510.27009">Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models</a> trained a 1.3B LLM on chess positions annotated with Stockfish. They do 200k steps at batch size 128, gradient accumulation 32 for an effective batch size of 4096 samples per step. At 200k steps that's about 820 million positions. The model achieved a measured Elo of ~2600, matching roughly grandmaster strength<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>.
</p>


<div id="org00fabfc" class="figure">
<p><img src="../images/from_clipboard/20251227_190606.png" alt="20251227_190606.png" />
</p>
</div>

<p>
I was really impressed by this paper! A 7B parameter model distilling stockfish this well would have been pretty mundane, but a 1.3B model being so successful opened up a world of possibilities, since fine-tuning a model of this size is not really a huge lift for somebody with the right expertise. They also point to <a href="https://arxiv.org/pdf/2402.04494">Ruoss et al 2024</a> which trained a smaller transformer (270M) from scratch on a much larger dataset to get an even better result (2895 rating)<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>.
</p>

<p>
<a href="https://openreview.net/pdf?id=baNBqpzvMT">Mixing Expert Knowledge: Bring Human Thoughts Back To the Game of Go</a> trained a 7B and 32B model on Go by distilling the moves from a strong RL model upon a language model cold-started with human annotations of Go positions.  This model reached 9d strength, which is very strong (but human level, compared to superhuman RL bots which crushed even the very best players). Critically, however, these models were able to provide <i>actual reasoning</i> for why the moves it selected were good or bad.
</p>


<div id="org60a0b16" class="figure">
<p><img src="../images/from_clipboard/20251227_191336.png" alt="20251227_191336.png" />
</p>
</div>

<p>
I saw this paper and promptly <i>flipped out</i> at the implications of it, it was by far my favorite result from NeurIPS 2025. Anybody who has tried to analyze their games with an engine has lots of experience not understanding why they should have done X move instead of Y move. This paper points to a future where you could just ask! There's a lot of interesting applications this opens up if the result holds for other settings, obviously making it relevant as a north star for our mahjong project. 
</p>
</div>
</div>

<div id="outline-container-orgb0a54fd" class="outline-2">
<h2 id="orgb0a54fd">Gathering Data</h2>
<div class="outline-text-2" id="text-orgb0a54fd">
<p>
Ample data from strong players is freely available, since mahjong players are playing mahjong roughly all the time. Amber from Path of Houou has posted a large database of <a href="https://pathofhouou.blogspot.com/2021/04/guide-replay-analysis.html">five years' worth of Tenhou replays</a> from strong players, which is a useful starting point for training something like this. Each year has about 250 thousand hanchans in it, so five years of games should result in roughly 1.25 million hanchans, which likely result in something like 800 million positions.
</p>

<p>
Previous examples mentioned will distill the policy of a very strong model (e.g. stockfish) by annotating every position with the oracle's top move. There exist strong RL-powered models for riichi mahjong like <a href="https://mjai.ekyu.moe/">Mortal</a> or MAKA, but these are not freely available to download, and do not offer batch processing for large quantities of games. However, it's possible we don't need to annotate games via the oracle at all.
</p>

<p>
In <a href="https://arxiv.org/abs/2406.11741v1">Transcendence: Generative Models Can Outperform The Experts That Train Them</a> they showed that models trained on low level chess games will produce a model which is stronger than any individual player. This is because bad moves can be framed as noise; on average bad players still play reasonable moves, and have decorrelated errors from one another<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>. Since <a href="https://arxiv.org/abs/1705.10694">Deep Learning is Robust to Massive Label Noise</a>, the resulting model is strong even when all the annotators are weak. Similar experiments were done even way back before chess computers were ubiquitous &#x2013; <a href="https://en.wikipedia.org/wiki/Kasparov_versus_the_World">Garry Kasparov vs The World</a> was one such game where thousands of players voted on what move to play against world champion Garry Kasparov, which produced an interesting and competitive game despite the average voter being way, way weaker than Kasparov.
</p>

<p>
Ergo, we will be training the model to be a pure imitation learning model, for now. This should simplify the workflow substantially at the starting phase of this project, since it's now just framed as a straightforward supervised learning problem the same way any other SFT workflow would be. It's likely that we won't get superhuman results with this approach, but that's just fine, that's not necessarily the goal.
</p>

<p>
On top of being performant at the game, a desirable behavior of the model is the ability to solve "2d problems" (i.e. positions without context from the other players) as well as "3d ones". Many <a href="https://euophrys.itch.io/mahjong-efficiency-trainer">training tools</a> and <a href="https://github.com/vg-mjg/301-wwyd-translation">improvement resources</a> are framed this way, since a 2d example is sufficient for capturing lots of important concepts like tile efficiency, block identification, maximizing expected value, and so on. We set aside a portion of the data which masks the discards and other players, to enable the model to answer questions like "what do you discard from this hand, in general?" 
</p>
</div>
</div>

<div id="outline-container-org37533e7" class="outline-2">
<h2 id="org37533e7">Training</h2>
<div class="outline-text-2" id="text-org37533e7">
<p>
To actually train this, since we have a relative lack of compute resources, I'll be using <a href="https://tinker-docs.thinkingmachines.ai/">Tinker</a> from Thinking Machines. This lab provides streamlined resources for finetuning language models of various sizes using <a href="https://arxiv.org/abs/2106.09685">Low Rank Adaptation</a> (LoRA). Tinker is nice since it will allow us to focus on data and training loop, rather than needing to fiddle with infrastructure. There's some concern with using LoRA over full finetuning, but <a href="https://thinkingmachines.ai/blog/lora/">they have a blogpost</a> outlining that LoRA is close enough in performance to full finetuning for post-training applications.
</p>

<p>
We choose Llama 3.2 1.3B as the primary model for this experiment, since it's inexpensive, fast, and was shown to be highly performant for chess in <a href="https://arxiv.org/pdf/2510.27009">Causal Masking on Spatial Data</a>. 
</p>
</div>

<div id="outline-container-orgbf7a0c5" class="outline-3">
<h3 id="orgbf7a0c5">Napkin Test I</h3>
<div class="outline-text-3" id="text-orgbf7a0c5">
<p>
As a quick napkin test, I finetuned llama-3.2-1B on ~500 positions and provided it with the following problem (one of my favorites, from G. Uzaku's Gold Book).
</p>


<div id="org0cb6777" class="figure">
<p><img src="../images/from_clipboard/20251227_160603.png" alt="20251227_160603.png" />
</p>
</div>

<p>
Dealer seat, 1m 2m 3m 3m 4m 5m 6m 7m 9m 3p 3p 7s 8s 9s, with 8s as the dora. 
</p>

<p>
This is a nice little test of a beginning player's grasp of the concepts. This hand is now in tenpai three different ways.
</p>

<ul class="org-ul">
<li>You can discard 6m and riichi for riichi dora 1 as dealer, waiting on the four 7m tiles.</li>
<li>You can discard 3m and riichi for riichi closed ittsu dora 1 as dealer, waiting on the four 7m tiles.</li>
<li>You can discard 9m and riichi for riichi pinfu dora 1 as dealer, waiting on the 10 remaining tiles of 2m/5m/8m.</li>
</ul>

<p>
The 6m is obviously worse than the other options, but an easy mistake to make is to discard the 3m here. Ittsu (pure straight in one suit) is flashy and pretty, and a four tile wait for a hand this big is pretty good<sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup>. But discarding the 9 gives you pinfu (i.e. destroying ittsu only loses 1 dora, not 2), lets you win with way more tiles (10 &gt; 4), and can win with red 5 for an extra han. 
</p>


<div id="org737d303" class="figure">
<p><img src="../images/from_clipboard/20251227_160616.png" alt="20251227_160616.png" />
</p>
</div>

<p>
The expected value is much better for the 9m. With just 500 examples I was happy to see the model understand that discarding the 3m was a potential candidate move, even if it's not quite correct (likely leveraging some prior knowledge about mahjong from pretraining, another nice advantage of using LLMs for a problem like this). Definitely a far cry from what we really want, but at this stage I was expecting "picks a legal move" to be a bigger hurdle than it ended up being. 
</p>


<div id="org9d97bfe" class="figure">
<p><img src="../images/from_clipboard/20251227_160639.png" alt="20251227_160639.png" />
</p>
</div>

<p>
With this I was confident enough to proceed with a larger training run.
</p>
</div>
</div>

<div id="outline-container-org0f76577" class="outline-3">
<h3 id="org0f76577">Training Run I</h3>
<div class="outline-text-3" id="text-org0f76577">
<p>
For the first "real" training run I scaled up to all the games in the 2016 database. This was about 250k hanchans, so it was a lot of data compared to the napkin test (but still small-ish by LLM standards). This was roughly one fifth of my data so it was a good kickstart for something like Tinker which is capacity constrained by using LoRA anyways<sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup>. It was a minor annoyance trying to scale this data up this much while keeping under memory constraints, since I couldn't just dump everything in an array and write it to a file at the end anymore<sup><a id="fnr.6" class="footref" href="#fn.6" role="doc-backlink">6</a></sup>.
</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
The Elo estimation from this paper is hazy since it uses winrate against various stockfish levels instead of human opponents. However, it's definitely still very strong. I was ~1600 blitz rating when I was an active chess player and it's tough for me to beat stockfish level 5-6.
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
This is definitely noteworthy but decidedly adjacent; the ultimate goal of our mahjong project here isn't to produce a strong riichi mahjong model per se (Mortal and others already do that), it's to train <i>a language model</i> which under the right circumstances could <i>explain its decisions</i>. We need something generally capable for that, which is why we highlight the language model despite its worse performance. 
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
This is obviously not <i>always true</i>. There are lots of positions where beginner players are all going to miss the critical move. But low level players will, for example, regularly make insane moves where they do not see their queen can be immediately captured by a knight on the next move. These are the types of errors which are trivially filtered through averaging.
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://ooyamaneko.net/download/mahjong/riichi/Daina_Chiba_-_Riichi_Book_1_en.pdf">Riichi Book I</a> is a good resource for judgment like this
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
It's possible that performance will saturate far below the use of all of my data regardless, so I didn't want to get ahead of myself. 
</p></div></div>

<div class="footdef"><sup><a id="fn.6" class="footnum" href="#fnr.6" role="doc-backlink">6</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
At this stage it was simple enough to just write as we go to a file, but it ended up being very very large (~150GB compared to the db of games itself only being 1.6GB). If I scale up past this I'll need to start considering using protobuf or some other efficient mechanism for serializing data.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<a href="#top">Back to Top</a>
</div>
</body>
</html>
